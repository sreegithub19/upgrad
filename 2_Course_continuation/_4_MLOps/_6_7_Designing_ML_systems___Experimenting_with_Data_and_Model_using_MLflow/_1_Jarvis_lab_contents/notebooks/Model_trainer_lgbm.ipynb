{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jdBp14QOVciC"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SUXpjbD6V-SE"
   },
   "outputs": [],
   "source": [
    "new_data = pd.read_csv(\"data_unseen.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "X1fCPPbuyvCf",
    "outputId": "aeb2c80f-d6c1-443c-9819-b32a65d50bb1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-3898e0c7-0d10-4dca-90f0-11e8d5c35724\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>city</th>\n",
       "      <th>bd</th>\n",
       "      <th>gender</th>\n",
       "      <th>registered_via</th>\n",
       "      <th>registration_init_time</th>\n",
       "      <th>is_churn</th>\n",
       "      <th>total_payment_channels</th>\n",
       "      <th>change_in_payment_methods</th>\n",
       "      <th>payment_plan_days_mean</th>\n",
       "      <th>change_in_plan</th>\n",
       "      <th>plan_list_price_mean</th>\n",
       "      <th>actual_amount_paid_mean</th>\n",
       "      <th>is_auto_renew_mean</th>\n",
       "      <th>is_autorenew_change_flag</th>\n",
       "      <th>transaction_date_min</th>\n",
       "      <th>transaction_date_max</th>\n",
       "      <th>total_transactions</th>\n",
       "      <th>membership_expire_date_max</th>\n",
       "      <th>is_cancel_mean</th>\n",
       "      <th>is_cancel_change_flag</th>\n",
       "      <th>discount_mean</th>\n",
       "      <th>is_discount_mean</th>\n",
       "      <th>is_discount_max</th>\n",
       "      <th>amt_per_day_mean</th>\n",
       "      <th>membership_duration_mean</th>\n",
       "      <th>more_than_30_sum</th>\n",
       "      <th>num_25</th>\n",
       "      <th>num_50</th>\n",
       "      <th>num_75</th>\n",
       "      <th>num_985</th>\n",
       "      <th>num_100</th>\n",
       "      <th>num_unq</th>\n",
       "      <th>total_secs</th>\n",
       "      <th>login_freq</th>\n",
       "      <th>last_login</th>\n",
       "      <th>registration_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X1AmJaNJ1bpGEgxLveRwBhxGHytaIHHuNfAAPFKCFg4=</td>\n",
       "      <td>1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2016-12-27</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-12-27</td>\n",
       "      <td>2017-02-27</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-03-26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>1.581984</td>\n",
       "      <td>0.934417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.230200</td>\n",
       "      <td>3.219675</td>\n",
       "      <td>9.070</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-02-04</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5obk4z2LF+rxlMWfs6GSj7p1HyFUYCvrsO6itixJIxk=</td>\n",
       "      <td>22</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2015-02-05</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>149.833333</td>\n",
       "      <td>149.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-06-18</td>\n",
       "      <td>2017-02-17</td>\n",
       "      <td>6</td>\n",
       "      <td>2017-03-19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.994444</td>\n",
       "      <td>30.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.296980</td>\n",
       "      <td>2.029523</td>\n",
       "      <td>5.953</td>\n",
       "      <td>12</td>\n",
       "      <td>2017-01-16</td>\n",
       "      <td>773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9eoVMtsXwWvmDtvBHzLTV5gegf59sdeuTvdbhnl77nk=</td>\n",
       "      <td>1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2016-12-27</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-12-27</td>\n",
       "      <td>2017-02-27</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-03-26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.838110</td>\n",
       "      <td>0.346574</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.758377</td>\n",
       "      <td>2.405943</td>\n",
       "      <td>7.695</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-02-05</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E7AzsekzVHL4d4ropO9g6HOwXUfsfrdM6FINWb6xTbs=</td>\n",
       "      <td>11</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-13</td>\n",
       "      <td>2017-02-13</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-03-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>29.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.069166</td>\n",
       "      <td>0.173287</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.543446</td>\n",
       "      <td>1.931663</td>\n",
       "      <td>7.145</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-02-17</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t2pAx7JJ+u9/tADRTYPb3EBqcDDk4M9JZIKG01FaagI=</td>\n",
       "      <td>5</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-01-11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-15</td>\n",
       "      <td>2017-01-15</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-02-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.748933</td>\n",
       "      <td>0.346574</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173287</td>\n",
       "      <td>3.310596</td>\n",
       "      <td>3.338761</td>\n",
       "      <td>9.030</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-01-22</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3898e0c7-0d10-4dca-90f0-11e8d5c35724')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-3898e0c7-0d10-4dca-90f0-11e8d5c35724 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-3898e0c7-0d10-4dca-90f0-11e8d5c35724');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                           msno  city    bd  gender  \\\n",
       "0  X1AmJaNJ1bpGEgxLveRwBhxGHytaIHHuNfAAPFKCFg4=     1   6.3       2   \n",
       "1  5obk4z2LF+rxlMWfs6GSj7p1HyFUYCvrsO6itixJIxk=    22  33.0       1   \n",
       "2  9eoVMtsXwWvmDtvBHzLTV5gegf59sdeuTvdbhnl77nk=     1   6.3       2   \n",
       "3  E7AzsekzVHL4d4ropO9g6HOwXUfsfrdM6FINWb6xTbs=    11  28.0       0   \n",
       "4  t2pAx7JJ+u9/tADRTYPb3EBqcDDk4M9JZIKG01FaagI=     5  28.0       0   \n",
       "\n",
       "   registered_via registration_init_time  is_churn  total_payment_channels  \\\n",
       "0              13             2016-12-27         0                       3   \n",
       "1               9             2015-02-05         0                       6   \n",
       "2              13             2016-12-27         0                       3   \n",
       "3               4             2017-01-09         0                       2   \n",
       "4               4             2017-01-11         1                       1   \n",
       "\n",
       "   change_in_payment_methods  payment_plan_days_mean  change_in_plan  \\\n",
       "0                          1                    30.0               1   \n",
       "1                          2                    30.0               1   \n",
       "2                          1                    30.0               1   \n",
       "3                          1                    30.0               1   \n",
       "4                          1                    30.0               1   \n",
       "\n",
       "   plan_list_price_mean  actual_amount_paid_mean  is_auto_renew_mean  \\\n",
       "0            100.000000               100.000000                 1.0   \n",
       "1            149.833333               149.833333                 0.0   \n",
       "2            129.000000               129.000000                 1.0   \n",
       "3            180.000000               180.000000                 1.0   \n",
       "4            180.000000               180.000000                 0.0   \n",
       "\n",
       "   is_autorenew_change_flag transaction_date_min transaction_date_max  \\\n",
       "0                         1           2016-12-27           2017-02-27   \n",
       "1                         0           2016-06-18           2017-02-17   \n",
       "2                         1           2016-12-27           2017-02-27   \n",
       "3                         1           2017-01-13           2017-02-13   \n",
       "4                         0           2017-01-15           2017-01-15   \n",
       "\n",
       "   total_transactions membership_expire_date_max  is_cancel_mean  \\\n",
       "0                   3                 2017-03-26             0.0   \n",
       "1                   6                 2017-03-19             0.0   \n",
       "2                   3                 2017-03-26             0.0   \n",
       "3                   2                 2017-03-13             0.0   \n",
       "4                   1                 2017-02-14             0.0   \n",
       "\n",
       "   is_cancel_change_flag  discount_mean  is_discount_mean  is_discount_max  \\\n",
       "0                      0            0.0               0.0                0   \n",
       "1                      0            0.0               0.0                0   \n",
       "2                      0            0.0               0.0                0   \n",
       "3                      0            0.0               0.0                0   \n",
       "4                      0            0.0               0.0                0   \n",
       "\n",
       "   amt_per_day_mean  membership_duration_mean  more_than_30_sum    num_25  \\\n",
       "0          3.333333                      29.0                 0  1.791759   \n",
       "1          4.994444                      30.5                 2  0.000000   \n",
       "2          4.300000                      29.0                 0  1.838110   \n",
       "3          6.000000                      29.5                 1  1.069166   \n",
       "4          6.000000                      30.0                 0  0.748933   \n",
       "\n",
       "     num_50    num_75   num_985   num_100   num_unq  total_secs  login_freq  \\\n",
       "0  1.581984  0.934417  0.000000  3.230200  3.219675       9.070           4   \n",
       "1  0.000000  0.000000  0.000000  5.296980  2.029523       5.953          12   \n",
       "2  0.346574  0.000000  0.693147  1.758377  2.405943       7.695           4   \n",
       "3  0.173287  0.000000  0.000000  1.543446  1.931663       7.145           4   \n",
       "4  0.346574  0.000000  0.173287  3.310596  3.338761       9.030           4   \n",
       "\n",
       "   last_login  registration_duration  \n",
       "0  2017-02-04                     89  \n",
       "1  2017-01-16                    773  \n",
       "2  2017-02-05                     89  \n",
       "3  2017-02-17                     63  \n",
       "4  2017-01-22                     34  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EF7oZgtr0vea"
   },
   "outputs": [],
   "source": [
    "def get_data_prepared_for_modeling(dataframe,scale_method='standard',date_columns=None,corr_threshold=0.90):\n",
    "    print(len(dataframe.columns))\n",
    "    # removingmulti-colinearity \n",
    "\n",
    "    # Create correlation matrix\n",
    "    corr_matrix = dataframe.corr().abs()\n",
    "    # Select upper triangle of correlation matrix\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "    # Find features with correlation greater than 0.95\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > corr_threshold)]\n",
    "    print(to_drop)\n",
    "    # Drop features \n",
    "    dataframe.drop(to_drop, axis=1, inplace=True)\n",
    "    print(len(dataframe.columns))\n",
    "\n",
    "    #date transformation \n",
    "    features = [\"day\",\"month\",\"year\",\"weekday\"]\n",
    "    date_data = dataframe[date_columns]\n",
    "    for eachcol in date_data:\n",
    "        date_data[eachcol] = date_data[eachcol].astype('str')\n",
    "        date_data[eachcol] = pd.to_datetime(date_data[eachcol]) \n",
    "        #column_name\n",
    "        for eachfeature in features:\n",
    "            col_name = f\"{eachcol}_{eachfeature}\"\n",
    "  \n",
    "            if eachfeature == 'day':\n",
    "                date_data[col_name] = date_data[eachcol].dt.day\n",
    "                # result[col_name] = result[col_name].astype('int64')\n",
    "            elif eachfeature == 'month':\n",
    "                date_data[col_name] = date_data[eachcol].dt.month\n",
    "                # result[col_name] = result[col_name].astype('int64')\n",
    "            elif eachfeature == 'year':\n",
    "                date_data[col_name] = date_data[eachcol].dt.year\n",
    "                # result[col_name] = result[col_name].astype('int64')\n",
    "            elif eachfeature == 'weekday':\n",
    "                date_data[col_name] = date_data[eachcol].dt.weekday\n",
    "    date_data.drop(date_columns,axis=1,inplace=True)\n",
    "    date_data = date_data.where(date_data.isna(), date_data.astype(str))\n",
    "    final_date = pd.get_dummies(date_data, drop_first=True,dtype='int16')\n",
    "    # print(pd.get_dummies(date_data, drop_first=True,dtype='int16')) \n",
    "  \n",
    "    #scaling\n",
    "    column_to_scale = new_data.select_dtypes(include=['float64','int64']).columns.drop('is_churn')\n",
    "    transformer = StandardScaler().fit(dataframe[column_to_scale])\n",
    "    scaled_data = pd.DataFrame(transformer.transform(dataframe[column_to_scale]),columns=column_to_scale)\n",
    "\n",
    "    #Combining \n",
    "    final_df = pd.concat([scaled_data,final_date,dataframe['is_churn']],axis=1)\n",
    "\n",
    "    #Splitting X,y \n",
    "    X = final_df.drop('is_churn',axis=1)\n",
    "    y = final_df[['is_churn']]\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x7Z_0_ArkLWT",
    "outputId": "c16e3a0c-c5f7-4cf1-fc45-eb48d93b27a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n",
      "['plan_list_price_mean', 'actual_amount_paid_mean', 'is_autorenew_change_flag', 'total_transactions', 'total_secs']\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "X,y = get_data_prepared_for_modeling(new_data,date_columns = ['registration_init_time','transaction_date_min','transaction_date_max','membership_expire_date_max','last_login'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import lightgbm as lgb\n",
    "\n",
    "def get_train_model(X,y):\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
    "  #Model Training\n",
    "  clf = lgb.LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
    "               device='gpu', importance_type='split', learning_rate=0.1,\n",
    "               max_depth=-1, min_child_samples=20, min_child_weight=0.001,\n",
    "               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,\n",
    "               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,\n",
    "               silent='warn', subsample=1.0, subsample_for_bin=200000,\n",
    "               subsample_freq=0)\n",
    "  clf.fit(X_train, y_train)\n",
    "  # predict the results\n",
    "  y_pred=clf.predict(X_test)\n",
    "  # view accuracy\n",
    "  accuracy=accuracy_score(y_pred, y_test)\n",
    "  print('LightGBM Model accuracy score: {0:0.4f}'.format(accuracy_score(y_test, y_pred)))\n",
    "  print(classification_report(y_test, y_pred))\n",
    "  print(confusion_matrix(y_test, y_pred))\n",
    "  return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predict(model,x):\n",
    "  return model.predict_proba(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full Pipeline \n",
    "\n",
    "#new data coming in with Y values \n",
    "X,y = get_data_prepared_for_modeling(new_data,date_columns = ['registration_init_time','transaction_date_min','transaction_date_max','membership_expire_date_max','last_login'])\n",
    "\n",
    "# Train the model with X & y \n",
    "model = get_train_model(X,y)\n",
    "\n",
    "#Predict Object \n",
    "predictions = get_predict(model,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A5pC6c0MXInS",
    "outputId": "4d418213-be54-4efd-e0df-0fe2ab02d90a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========Training fold 0==========\n",
      "LightGBM Model accuracy score: 0.9654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       755\n",
      "           1       0.78      0.69      0.73        55\n",
      "\n",
      "    accuracy                           0.97       810\n",
      "   macro avg       0.88      0.84      0.86       810\n",
      "weighted avg       0.96      0.97      0.96       810\n",
      "\n",
      "[[744  11]\n",
      " [ 17  38]]\n",
      "==========Training fold 1==========\n",
      "LightGBM Model accuracy score: 0.9580\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       755\n",
      "           1       0.70      0.67      0.69        55\n",
      "\n",
      "    accuracy                           0.96       810\n",
      "   macro avg       0.84      0.83      0.83       810\n",
      "weighted avg       0.96      0.96      0.96       810\n",
      "\n",
      "[[739  16]\n",
      " [ 18  37]]\n",
      "==========Training fold 2==========\n",
      "LightGBM Model accuracy score: 0.9580\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       755\n",
      "           1       0.70      0.67      0.69        55\n",
      "\n",
      "    accuracy                           0.96       810\n",
      "   macro avg       0.84      0.83      0.83       810\n",
      "weighted avg       0.96      0.96      0.96       810\n",
      "\n",
      "[[739  16]\n",
      " [ 18  37]]\n",
      "==========Training fold 3==========\n",
      "LightGBM Model accuracy score: 0.9642\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       755\n",
      "           1       0.78      0.65      0.71        55\n",
      "\n",
      "    accuracy                           0.96       810\n",
      "   macro avg       0.88      0.82      0.85       810\n",
      "weighted avg       0.96      0.96      0.96       810\n",
      "\n",
      "[[745  10]\n",
      " [ 19  36]]\n",
      "==========Training fold 4==========\n",
      "LightGBM Model accuracy score: 0.9580\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       755\n",
      "           1       0.72      0.62      0.67        55\n",
      "\n",
      "    accuracy                           0.96       810\n",
      "   macro avg       0.85      0.80      0.82       810\n",
      "weighted avg       0.96      0.96      0.96       810\n",
      "\n",
      "[[742  13]\n",
      " [ 21  34]]\n",
      "==========Training fold 5==========\n",
      "LightGBM Model accuracy score: 0.9704\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       755\n",
      "           1       0.86      0.67      0.76        55\n",
      "\n",
      "    accuracy                           0.97       810\n",
      "   macro avg       0.92      0.83      0.87       810\n",
      "weighted avg       0.97      0.97      0.97       810\n",
      "\n",
      "[[749   6]\n",
      " [ 18  37]]\n",
      "==========Training fold 6==========\n",
      "LightGBM Model accuracy score: 0.9568\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       755\n",
      "           1       0.72      0.60      0.65        55\n",
      "\n",
      "    accuracy                           0.96       810\n",
      "   macro avg       0.84      0.79      0.82       810\n",
      "weighted avg       0.95      0.96      0.95       810\n",
      "\n",
      "[[742  13]\n",
      " [ 22  33]]\n",
      "==========Training fold 7==========\n",
      "LightGBM Model accuracy score: 0.9556\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       754\n",
      "           1       0.69      0.64      0.67        56\n",
      "\n",
      "    accuracy                           0.96       810\n",
      "   macro avg       0.83      0.81      0.82       810\n",
      "weighted avg       0.95      0.96      0.95       810\n",
      "\n",
      "[[738  16]\n",
      " [ 20  36]]\n",
      "==========Training fold 8==========\n",
      "LightGBM Model accuracy score: 0.9568\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98       754\n",
      "           1       0.68      0.71      0.70        56\n",
      "\n",
      "    accuracy                           0.96       810\n",
      "   macro avg       0.83      0.84      0.84       810\n",
      "weighted avg       0.96      0.96      0.96       810\n",
      "\n",
      "[[735  19]\n",
      " [ 16  40]]\n",
      "==========Training fold 9==========\n",
      "LightGBM Model accuracy score: 0.9568\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       754\n",
      "           1       0.69      0.68      0.68        56\n",
      "\n",
      "    accuracy                           0.96       810\n",
      "   macro avg       0.83      0.83      0.83       810\n",
      "weighted avg       0.96      0.96      0.96       810\n",
      "\n",
      "[[737  17]\n",
      " [ 18  38]]\n",
      "==========Training fold 10==========\n",
      "LightGBM Model accuracy score: 0.9457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       754\n",
      "           1       0.61      0.61      0.61        56\n",
      "\n",
      "    accuracy                           0.95       810\n",
      "   macro avg       0.79      0.79      0.79       810\n",
      "weighted avg       0.95      0.95      0.95       810\n",
      "\n",
      "[[732  22]\n",
      " [ 22  34]]\n",
      "==========Training fold 11==========\n",
      "LightGBM Model accuracy score: 0.9593\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       754\n",
      "           1       0.74      0.62      0.68        56\n",
      "\n",
      "    accuracy                           0.96       810\n",
      "   macro avg       0.86      0.80      0.83       810\n",
      "weighted avg       0.96      0.96      0.96       810\n",
      "\n",
      "[[742  12]\n",
      " [ 21  35]]\n",
      "==========Training fold 12==========\n",
      "LightGBM Model accuracy score: 0.9605\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       754\n",
      "           1       0.72      0.70      0.71        56\n",
      "\n",
      "    accuracy                           0.96       810\n",
      "   macro avg       0.85      0.84      0.84       810\n",
      "weighted avg       0.96      0.96      0.96       810\n",
      "\n",
      "[[739  15]\n",
      " [ 17  39]]\n",
      "==========Training fold 13==========\n",
      "LightGBM Model accuracy score: 0.9556\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       754\n",
      "           1       0.69      0.64      0.67        56\n",
      "\n",
      "    accuracy                           0.96       810\n",
      "   macro avg       0.83      0.81      0.82       810\n",
      "weighted avg       0.95      0.96      0.95       810\n",
      "\n",
      "[[738  16]\n",
      " [ 20  36]]\n",
      "==========Training fold 14==========\n",
      "LightGBM Model accuracy score: 0.9593\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       754\n",
      "           1       0.74      0.62      0.68        56\n",
      "\n",
      "    accuracy                           0.96       810\n",
      "   macro avg       0.86      0.80      0.83       810\n",
      "weighted avg       0.96      0.96      0.96       810\n",
      "\n",
      "[[742  12]\n",
      " [ 21  35]]\n",
      "==========Training fold 15==========\n",
      "LightGBM Model accuracy score: 0.9691\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       754\n",
      "           1       0.84      0.68      0.75        56\n",
      "\n",
      "    accuracy                           0.97       810\n",
      "   macro avg       0.91      0.83      0.87       810\n",
      "weighted avg       0.97      0.97      0.97       810\n",
      "\n",
      "[[747   7]\n",
      " [ 18  38]]\n",
      "==========Training fold 16==========\n",
      "LightGBM Model accuracy score: 0.9605\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       754\n",
      "           1       0.75      0.64      0.69        56\n",
      "\n",
      "    accuracy                           0.96       810\n",
      "   macro avg       0.86      0.81      0.84       810\n",
      "weighted avg       0.96      0.96      0.96       810\n",
      "\n",
      "[[742  12]\n",
      " [ 20  36]]\n",
      "==========Training fold 17==========\n",
      "LightGBM Model accuracy score: 0.9679\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       754\n",
      "           1       0.83      0.68      0.75        56\n",
      "\n",
      "    accuracy                           0.97       810\n",
      "   macro avg       0.90      0.83      0.86       810\n",
      "weighted avg       0.97      0.97      0.97       810\n",
      "\n",
      "[[746   8]\n",
      " [ 18  38]]\n",
      "==========Training fold 18==========\n",
      "LightGBM Model accuracy score: 0.9494\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       754\n",
      "           1       0.65      0.57      0.61        56\n",
      "\n",
      "    accuracy                           0.95       810\n",
      "   macro avg       0.81      0.77      0.79       810\n",
      "weighted avg       0.95      0.95      0.95       810\n",
      "\n",
      "[[737  17]\n",
      " [ 24  32]]\n",
      "==========Training fold 19==========\n",
      "LightGBM Model accuracy score: 0.9543\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       754\n",
      "           1       0.69      0.61      0.65        56\n",
      "\n",
      "    accuracy                           0.95       810\n",
      "   macro avg       0.83      0.79      0.81       810\n",
      "weighted avg       0.95      0.95      0.95       810\n",
      "\n",
      "[[739  15]\n",
      " [ 22  34]]\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgbm\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "num_splits = 20\n",
    "strat_kf = StratifiedKFold(n_splits=num_splits, shuffle=True, random_state=42)\n",
    "\n",
    "scores = np.empty(N_SPLITS)\n",
    "for idx, (train_idx, test_idx) in enumerate(strat_kf.split(X, y)):\n",
    "    print(\"=\" * 10 + f\"Training fold {idx}\" + 10 * \"=\")\n",
    "\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    eval_set = [(X_val, y_val)]\n",
    "\n",
    "    lgbm_clf = lgbm.LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
    "               importance_type='split', learning_rate=0.1,\n",
    "               max_depth=-1, min_child_samples=20, min_child_weight=0.001,\n",
    "               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,\n",
    "               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,\n",
    "               silent='warn', subsample=1.0, subsample_for_bin=200000,\n",
    "               subsample_freq=0)\n",
    "    lgbm_clf.fit(X_train, y_train)\n",
    "    # predict the results\n",
    "    y_pred=lgbm_clf.predict(X_val)\n",
    "    # view accuracy\n",
    "    accuracy=accuracy_score(y_val, y_pred)\n",
    "    print('LightGBM Model accuracy score: {0:0.4f}'.format(accuracy))\n",
    "    print(classification_report(y_val, y_pred))\n",
    "    print(confusion_matrix(y_val, y_pred))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Model trainer_lgbm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
