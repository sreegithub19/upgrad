{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d96229d1",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "> Imagine you are working as a data scientist at a home electronics company which manufactures\n",
    "state of the art smart televisions. You want to develop a cool feature in the smart-TV that can\n",
    "recognise five different gestures performed by the user which will help users control the TV\n",
    "without using a remote\n",
    "The gestures are continuously monitored by the webcam mounted on the TV. Each gesture\n",
    "corresponds to a specific command:\n",
    "- Thumbs up: Increase the volume\n",
    "- Thumbs down: Decrease the volume\n",
    "- Left swipe: 'Jump' backwards 10 seconds\n",
    "- Right swipe: 'Jump' forward 10 seconds\n",
    "- Stop: Pause the movie\n",
    "- Each video is a sequence of 30 frames (or images)\n",
    "\n",
    "# Understanding the Dataset\n",
    "\n",
    "- The training data consists of a few hundred videos categorised into one of the five classes. Each video (typically 2-3 seconds long) is divided into a sequence of 30 frames(images). These videos have been recorded by various people performing one of the five gestures in front of a webcam similar to what the smart TV will use.\n",
    "\n",
    "- - The data is in a zip file.\n",
    "- - The zip file contains a 'train' and a 'val' folder with two CSV files for the two folders.\n",
    "\n",
    "# Objective\n",
    "\n",
    "- Our task is to train different models on the 'train' folder to predict the action performed in each sequence or video and which performs well on the 'val' folder as well. The final test folder for evaluation is withheld - final model's performance will be tested on the 'test' set.\n",
    "\n",
    "- Two types of architectures suggested for analyzing videos using deep learning:\n",
    "\n",
    "## Model Description:\n",
    "> ### 1. 3D Convolutional Neural Networks (Conv3D)\n",
    "- 3D convolutions are a natural extension to the 2D convolutions you are already familiar with.Just like in 2D conv, you move the filter in two directions (x and y), in 3D conv, you move the filter in three directions (x, y and z). In this case, the input to a 3D conv is a video (which is a sequence of 30 RGB images). If we assume that the shape of each image is 100 x 100 x 3, for example, the video becomes a 4D tensor of shape 100 x 100 x 3 x 30 which can be written as (100 x 100 x 30) x 3 where 3 is the number of channels. Hence, deriving the analogy from 2D convolutions where a 2D kernel/filter (a square filter) is represented as (f x f) x c where f is filter size and c is the number of channels, a 3D kernel/filter (a 'cubic' filter) is represented as (f x f x f)\n",
    "x c (here c = 3 since the input images have three channels). This cubic filter will now '3Dconvolve' on each of the three channels of the (100 x 100 x 30) tensor.\n",
    "\n",
    "> ### 2. CNN + RNN architecture\n",
    "\n",
    "- The conv2D network will extract a feature vector for each image, and a sequence of these feature vectors is then fed to an RNN-based network. The output of the RNN is a regular softmax (for a classification problem such as this one).\n",
    "\n",
    "> Data Generator\n",
    "This is one of the most important parts of the code. In the generator, we are going to preprocess the images as we have images of different dimensions (50 x 50, 70 x 70 and 120 x 120) as well as create a batch of video frames. The generator should be able to take a batch of videos as input without any error. Steps like cropping/resizing and normalization should be performed successfully.\n",
    "\n",
    "> Data Pre-processing\n",
    "\n",
    "- Resizing. This was mainly done to ensure that the NN only recognizes the gestures\n",
    "effectively.\n",
    "- Normalization of the images. Normalizing the RGB values of an image can at times be a simple and effective way to get rid of distortions caused by lights and shadows in an image.\n",
    "\n",
    "> NN Architecture development and training\n",
    "\n",
    "- - Experimented with different model configurations and hyper-parameters and various iterations and combinations of batch sizes, image dimensions, filter sizes, padding and stride length were experimented with. We also played around with different learning rates and ReduceLROnPlateau was used to decrease the learning rate if the monitored metrics (val_loss) remains unchanged in between epochs.\n",
    "\n",
    "- - We experimented with SGD() and Adam() optimizers but went forward with SGD as it lead to improvement in model�s accuracy by rectifying high variance in the model�s parameters. Played with multiple parameters of the SGD like decay_rate, starting learning rate.\n",
    "\n",
    "- - We also made use of Batch Normalization, pooling and dropout layers when our model started to overfit, this could be easily witnessed when our model started giving poor validation accuracy in spite of having good training accuracy.\n",
    "\n",
    "- - Early stopping was used to put a halt at the training process when the val_loss would start to saturate / model�s performance would stop improving.\n",
    "Observations\n",
    "\n",
    "- - It was observed that as the Number of trainable parameters increase, the model takes much more time for training.\n",
    "- - Batch size ? GPU memory / available compute. A large batch size can throw GPU Out of memory error (e.g 64 on cloud platform and 25 in local GPU), and thus here we had to play around with the batch size till we were able to arrive at an optimal value of the batch size which our GPU could support ( NVIDIA GTX 1650 and RTX 5000 in Jarvis Labs).\n",
    "- - We also found out that the middle frames gives us most of the information and because the train images were chosen so carefully, data augmentation was not required though left-right flipping and zoom, slight rotation could have been done.\n",
    "- - Increasing the batch size greatly reduces the training time but this also has a negative impact on the model accuracy. This made us realise that there is always a trade-off here on basis of priority -> If we want our model to be ready in a shorter time span, choose larger batch size else you should choose lower batch size if you want your model to be more accurate.\n",
    "- -  Conv3D had better performance than CNN+LSTM based model with GRU cells. As per our understanding, this is something which depends on the kind of data we used, the architecture we developed and the hyper-parameters we chose.\n",
    "- - Transfer learning boosted the overall accuracy of the model. We made use of the MobileNet Architecture due to its light weight design and high-speed performance coupled with low maintenance as compared to other well-known architectures like VGG16, AlexNet, GoogleNet etc. \n",
    "\n",
    "\n",
    "\n",
    "## Conclusion: Transfer learning model worked best for us with all the layers trainable, we can see the conv3d played well from the time distributed one which are enough to test on the image set.\n",
    "\n",
    "\n",
    "- # Model Statistics\n",
    "\n",
    "- # Conv3D\n",
    "\n",
    "- Model 1 : No of Epochs = 15 , batch_size = 64 ,shape = (120,120) , no of frames = 10\n",
    "- - - - Model 1 is giving the out of memory error with batch size 64. We try with less batch size and shapes to further improve the performance and accuracy\n",
    "\n",
    "- Model 2 : No of Epochs = 20 , batch_size = 20 ,shape = (50,50) , no of frames = 6\n",
    "\n",
    "- - - - Training Accuracy : 95.74% , Validation Accuracy : 89% , \n",
    "- - - - Model Analysis : Training and validation Accuracy are good so that we can conclude that with above set of parameters model is giving good results\n",
    "\n",
    "- Model 3 : No of Epochs = 20 , batch_size = 30 ,shape = (50,50) , no of frames = 10\n",
    "\n",
    "- - - - Training Accuracy : 95.29% , Validation Accuracy : 87% \n",
    "- - - - Model Analysis : Keeping the same shape and increasing the number of frames we have observed that accuracy increased but seems to be overfitting as compared to Model-2\n",
    "\n",
    "- Model 4 : No of Epochs = 25 , batch_size = 50 ,shape = (100,100) , no of frames = 10\n",
    "\n",
    "- - - - Training Accuracy : 91.71% , Validation Accuracy : 86% \n",
    "- - - - Model Analysis : Increasing the image size decreases the accuracy. Also, this model seems to be overfitting.\n",
    "\n",
    "- Model 5 : No of Epochs = 25 , Batch_size = 50 , shape = (70,70) , no of frames = 18 \n",
    "\n",
    "- - - - Training Accuracy : 95.71% , Validation Accuracy : 87% \n",
    "- - - - Model Analysis : This model is clearly an overfit model can see that increasing in number of frames and epochs causing the noise to be learned also from all the frames\n",
    "\n",
    "- # CNN + RNN : CNN2D LSTM Model - TimeDistributed\n",
    "\n",
    "- Model 6 : No of Epochs = 25 , Batch_size = 50 , shape = (70,70) , no of frames = 18 \n",
    "\n",
    "- - - - Training Accuracy : 81.79% , Validation Accuracy : 60% \n",
    "- - - - Model Analysis : This model is clearly Overfitting\n",
    "\n",
    "- Model 7 : No of epochs = 20 , batch_size = 20 , shape  (50,50) , no of frames  = 10 \n",
    "\n",
    "- - - - Training Accuracy : 84.71% , Validation Accuracy : 67% \n",
    "- - - - Model Analysis : This model is clearly overfitting\n",
    "\n",
    "- # CONV2D + GRU\n",
    "\n",
    "- Model 8 : No of epochs = 20 , batch_size = 20 , shape  (50,50) , no of frames  = 18\n",
    "\n",
    "- - - - Training Accuracy : 94.26%, Validation Accuracy : 72% \n",
    "- - - - Model Analysis : This model is overfitting\n",
    "\n",
    "- # Transfer Learning Using MobileNet\n",
    "\n",
    "-  Model 9 : No of epochs = 15 , batch_size = 5 , shape  (120,120) , no of frames  = 18\n",
    "\n",
    "- - - - Training Accuracy : 99.55% , Validation Accuracy : 95% \n",
    "- - - - Model Analysis : This is so far the best model that we got with better accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07156132",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
